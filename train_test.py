import numpy as np
import csv
import json
from collections import defaultdict
import tensorflow as tf
from tensorflow.keras.models import Model, load_model
from sklearn.preprocessing import RobustScaler
from keras.layers import Dense
from sklearn.metrics import classification_report, confusion_matrix
from utils import add_gestures
from model import create_model
from loss import grad


def train_test_model(X_train_source, X_train_target, y_train_target, X_test_target, y_test_target,
                     model_cfg, label_maps):
    """
    Train and evaluate the model in a few-shot continual learning way

    Args:
        X_train_source: data from control participants
        X_train_target: train data from the impaired participant
        y_train_target: true train labels for the gesture classes
        X_test_target: test data from the impaired participant
        y_test_target: true test labels for the gesture classes
        model_cfg: config instance to access the hyperparameters
        label_maps: gesture dictionary based on an order

    """
    # Save average precision, recall and F1-score in a csv file
    csvfile_prf = open('avg_metric_score_gesture.csv', 'w', encoding='utf-8')
    csvfile_writer_prf = csv.writer(csvfile_prf)
    csvfile_writer_prf.writerow(["number of samples", "gesture", "avg_precision", "avg_recall", "avg_f1_score"])

    # Save average accuracy in a csv file
    csvfile_acc = open('avg_acc_gesture.csv', 'w', encoding='utf-8')
    csvfile_writer_acc = csv.writer(csvfile_acc)
    csvfile_writer_acc.writerow(["number of samples", "number of gestures", "avg_accuracy"])

    cm = defaultdict(list)
    number_of_gestures = 6
    start = 2  # initialize with two gestures
    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)

    model = load_model('./saved_model/pre-trained_model.h5')
    intermediate_model = Model(inputs=model.input, outputs=model.layers[2].output)
    embeddings_control = intermediate_model(X_train_source)

    for cur in range(start, number_of_gestures + 1):  # iterate over the gestures. starts using labels: 0 and 1.

        copy_model = load_model('./saved_model/pre-trained_model.h5')
        intermediate_copy_model = Model(inputs=copy_model.input, outputs=copy_model.layers[2].output)

        gesture_labels = [i for i in range(cur)]  # gesture labels in order

        shots = []

        cls_ges_pre = defaultdict(list)
        cls_ges_rec = defaultdict(list)
        cls_ges_f1 = defaultdict(list)

        count = 1

        X_train_n, y_train_n = add_gestures(X_train_target, y_train_target, cur)
        X_test_n, y_test_n = add_gestures(X_test_target, y_test_target, cur)

        target_names = list(label_maps.keys())[:cur]
        while count:  # adding 1 sample, 3 samples and 5 samples consecutively.
            X_train_f = []
            y_train_f = []
            c = {}
            for i in gesture_labels:
                c[i] = 0
            for label in range(len(y_train_n)):
                if c[y_train_n[label]] != count:
                    X_train_f.append(X_train_n[label])
                    y_train_f.append(y_train_n[label])
                    c[y_train_n[label]] += 1

            X_train_n_arr = np.array(X_train_f)  # converting list to array (train set)
            y_train_n_arr = np.array(y_train_f)

            X_test_n_arr = np.array(X_test_n)  # converting list to array (test set)
            y_test_n_arr = np.array(y_test_n)

            scaler = RobustScaler()
            X_train_n_arr = scaler.fit_transform(X_train_n_arr.reshape(-1, X_train_n_arr.shape[-1])).reshape(
                X_train_n_arr.shape)
            X_test_n_arr = scaler.transform(X_test_n_arr.reshape(-1, X_test_n_arr.shape[-1])).reshape(
                X_test_n_arr.shape)

            # Temporary latent embedding of impaired samples
            embeddings_impaired_fixed = intermediate_copy_model(X_train_n_arr)

            cls_ges_sum_pre = defaultdict(list)
            cls_ges_sum_rec = defaultdict(list)
            cls_ges_sum_f1 = defaultdict(list)
            cls_acc = []

            for i in range(model_cfg['num_iteration']):
                train_model = create_model(model_cfg['time_steps'], model_cfg['features'], model_cfg['dimension1'],
                                           model_cfg['dropout'], model_cfg['dimension2'], model_cfg['num_classes'])
                train_model.load_weights('./saved_model/pre-trained_model_weights.h5')
                train_model.pop()
                train_model.add(Dense(len(gesture_labels), activation='softmax'))
                train_model.summary()
                for epoch in range(model_cfg['epochs']):
                    intermediate_train_model = Model(inputs=train_model.input, outputs=train_model.layers[2].output)
                    embeddings_impaired = intermediate_train_model(X_train_n_arr)

                    loss_value, grads = grad(train_model, X_train_n_arr, y_train_n_arr, embeddings_control,
                                             embeddings_impaired_fixed, embeddings_impaired)
                    optimizer.apply_gradients(zip(grads, train_model.trainable_variables))

                y_pre = np.argmax(train_model.predict(X_test_n_arr), axis=-1)
                cm[cur].append(confusion_matrix(y_test_n_arr, y_pre))

                report = classification_report(y_test_n_arr, y_pre, target_names=target_names)

                # Store all iterations' precision, recall and F1-score for each gesture from the classification report
                for item in target_names:
                    precision = float(report.split(item)[1].split()[0])
                    recall = float(report.split(item)[1].split()[1])
                    f1_score = float(report.split(item)[1].split()[2])

                    cls_ges_sum_pre[item].append(precision)
                    cls_ges_sum_rec[item].append(recall)
                    cls_ges_sum_f1[item].append(f1_score)

                cls_acc.append(float(report.split('accuracy')[1].split()[0]))

            # Save the average precision, recall and F1-score for each gesture
            for n in target_names:
                cls_ges_pre[n].append(np.mean(cls_ges_sum_pre[n]))
                cls_ges_rec[n].append(np.mean(cls_ges_sum_rec[n]))
                cls_ges_f1[n].append(np.mean(cls_ges_sum_f1[n]))

                avg_pre = np.mean(cls_ges_sum_pre[n])
                avg_rec = np.mean(cls_ges_sum_rec[n])
                avg_f1 = np.mean(cls_ges_sum_f1[n])

                csv_line_prf = [count, n, avg_pre, avg_rec, avg_f1]
                csvfile_writer_prf.writerow(csv_line_prf)

            csv_line_acc = [count, len(gesture_labels), np.mean(cls_acc)]
            csvfile_writer_acc.writerow(csv_line_acc)

            shots.append(count)
            count += 2
            if count > 6:
                break
    csvfile_prf.close()
    csvfile_acc.close()

    # Save confusion matrices as a json file
    for key, value in cm.items():
        cm[key] = [arr.tolist() for arr in value]
    with open('cm_file.json', 'w') as f:
        json.dump(cm, f)
