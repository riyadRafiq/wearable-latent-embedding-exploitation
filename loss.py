import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from scipy import spatial
import tensorflow as tf


def cosine_similarity_loss(embd_one, embd_two, maximize):
    """
    Calculates loss in terms of cosine similarity

    Args:
        embd_one: one latent embedding
        embd_two: other latent embedding
        maximize (bool): if true, the cosine similarity is maximized,
                        otherwise false

    Returns:
         The loss value
    """
    if maximize:
        cos_sim = cosine_similarity(embd_one, embd_two)
        loss = 1.0 - np.mean(cos_sim)
    else:
        embd_one_flat = np.hstack(embd_one)
        embd_two_flat = np.hstack(embd_two)
        cos_sim = 1.0 - spatial.distance.cosine(embd_one_flat, embd_two_flat)
        loss = cos_sim

    return loss


def classification_loss(y_true, y_pre):
    """
    Calculates the classification loss

    Args:
        y_true: true labels of classes
        y_pre: predicted labels

    Returns:
         The loss value
    """
    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()

    return loss_object(y_true, y_pre)


def overall_loss(model, inputs, targets, embd_c, embd_if, embd_i):
    """
    Calculates the total loss

    Args:
        model: model instance
        inputs: data
        targets: true labels of classes
        embd_c: latent embedding from control participants
        embd_if: latent embedding from the impaired participant (temporary embedding)
        embd_i: latent embedding from the impaired participant (learned embedding)

    Returns:
         The total loss value
    """

    alpha = 0.5  # we select 0.5
    loss_con_imp = cosine_similarity_loss(embd_c, embd_i, True)
    loss_imp_imp = cosine_similarity_loss(embd_if, embd_i, False)
    loss_cls = classification_loss(targets, model(inputs, training=True))
    total_loss = (alpha * loss_con_imp) + ((1.0 - alpha) * loss_imp_imp) + loss_cls

    return total_loss


def grad(model, inputs, targets, embd_c, embd_if, embd_i):
    with tf.GradientTape() as tape:
        loss_value = overall_loss(model, inputs, targets, embd_c, embd_if, embd_i)

    return loss_value, tape.gradient(loss_value, model.trainable_variables)
